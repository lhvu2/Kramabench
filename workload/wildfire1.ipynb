{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04903861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cfbc6c",
   "metadata": {},
   "source": [
    "## Q1: Find the 3-month period with the highest total acres burned since Jan 2000, according to NOAA. What was the total acres burned in that period?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6edf255",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/wildfire/input/noaa_wildfires.csv\", skiprows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4020b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Start Date': np.int64(201506), 'End Date': np.int64(201508), 'Total Acres Burned': np.int64(7805421), 'Period Data':        Date  Acres Burned  Number of Fires  Acres Burned per Fire\n",
      "185  201506       1868614             6430                 290.61\n",
      "186  201507       3461087             8186                 422.81\n",
      "187  201508       2475720             7555                 327.69}\n"
     ]
    }
   ],
   "source": [
    "df = df.sort_values('Date')\n",
    "    \n",
    "# Create a function to check if dates are consecutive months\n",
    "def are_consecutive(date1, date2):\n",
    "    year1, month1 = divmod(date1, 100)\n",
    "    year2, month2 = divmod(date2, 100)\n",
    "\n",
    "    # Convert to total months\n",
    "    total_months1 = year1 * 12 + month1\n",
    "    total_months2 = year2 * 12 + month2\n",
    "\n",
    "    return total_months2 - total_months1 == 1\n",
    "\n",
    "max_acres = 0\n",
    "max_period = None\n",
    "\n",
    "# Iterate through possible 3-month periods\n",
    "for i in range(len(df) - 2):\n",
    "    # Check if months are consecutive\n",
    "    if (are_consecutive(df['Date'].iloc[i], df['Date'].iloc[i+1]) and \n",
    "        are_consecutive(df['Date'].iloc[i+1], df['Date'].iloc[i+2])):\n",
    "\n",
    "        # Calculate total acres for this period\n",
    "        period_acres = df['Acres Burned'].iloc[i:i+3].sum()\n",
    "\n",
    "        # Update maximum if this period is larger\n",
    "        if period_acres > max_acres:\n",
    "            max_acres = period_acres\n",
    "            max_period = df.iloc[i:i+3]\n",
    "\n",
    "print({\n",
    "    'Start Date': max_period['Date'].iloc[0],\n",
    "    'End Date': max_period['Date'].iloc[-1],\n",
    "    'Total Acres Burned': max_acres,\n",
    "    'Period Data': max_period\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef02938d",
   "metadata": {},
   "source": [
    "## Q2: Which NIFC geographic area intersects with the most US states? Give the abbreviation of the geographic area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5da517a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eylai/Projects/LLMBenchmark/.venv/lib/python3.10/site-packages/pyogrio/raw.py:198: RuntimeWarning: Non-conformant content for record 1 in column DateCurrent, 2022-01-03T16:37:52.0Z, successfully parsed\n",
      "  return ogr_read(\n"
     ]
    }
   ],
   "source": [
    "gdf_usa = gpd.read_file(\"../data/wildfire/input/usa.gpkg\")\n",
    "gdf_nifc = gpd.read_file(\"../data/wildfire/input/nifc_geographic_areas.gpkg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2666c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NIFC Geographic Area(s) intersecting with the most states:\n",
      "\n",
      "GACC Name: Eastern Area Coordination Center\n",
      "GACC Abbreviation: EACC\n",
      "Number of intersecting states: 30\n",
      "States: Arkansas, Connecticut, Delaware, District of Columbia, Illinois, Indiana, Iowa, Kansas, Kentucky, Maine, Maryland, Massachusetts, Michigan, Minnesota, Missouri, Nebraska, New Hampshire, New Jersey, New York, North Dakota, Ohio, Oklahoma, Pennsylvania, Rhode Island, South Dakota, Tennessee, Vermont, Virginia, West Virginia, Wisconsin\n"
     ]
    }
   ],
   "source": [
    "# Ensure same CRS\n",
    "gdf_nifc = gdf_nifc.to_crs(gdf_usa.crs)\n",
    "\n",
    "# Dissolve state geometries\n",
    "gdf_usa_dissolved = gdf_usa.dissolve(by='adm1_name', as_index=False)\n",
    "\n",
    "# Perform spatial join\n",
    "joined = gpd.sjoin(gdf_usa_dissolved, gdf_nifc, how='right', predicate='intersects')\n",
    "\n",
    "# Group by NIFC region and aggregate both count and list of states\n",
    "result = (joined.groupby(['GACCName', 'GACCAbbreviation'])\n",
    "          .agg({\n",
    "              'adm1_name': [('Number_of_States', 'nunique'),\n",
    "                           ('States', lambda x: list(set(x)))]\n",
    "          })\n",
    "          .reset_index())\n",
    "\n",
    "# Flatten column names\n",
    "result.columns = ['GACC_Name', 'GACC_Abbreviation', 'Number_of_States', 'States']\n",
    "\n",
    "# Sort by number of states (descending)\n",
    "result = result.sort_values('Number_of_States', ascending=False)\n",
    "\n",
    "# Get the region(s) with the maximum number of states\n",
    "max_states = result['Number_of_States'].max()\n",
    "top_regions = result[result['Number_of_States'] == max_states]\n",
    "\n",
    "print(\"\\nNIFC Geographic Area(s) intersecting with the most states:\")\n",
    "for _, row in top_regions.iterrows():\n",
    "    print(f\"\\nGACC Name: {row['GACC_Name']}\")\n",
    "    print(f\"GACC Abbreviation: {row['GACC_Abbreviation']}\")\n",
    "    print(f\"Number of intersecting states: {row['Number_of_States']}\")\n",
    "    print(\"States:\", \", \".join(sorted(row['States'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6e5804",
   "metadata": {},
   "source": [
    "## Q3: Which US states fall into the most number of NIFC Geographic Areas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03187f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eylai/Projects/LLMBenchmark/.venv/lib/python3.10/site-packages/pyogrio/raw.py:198: RuntimeWarning: Non-conformant content for record 1 in column DateCurrent, 2022-01-03T16:37:52.0Z, successfully parsed\n",
      "  return ogr_read(\n"
     ]
    }
   ],
   "source": [
    "gdf_usa = gpd.read_file(\"../data/wildfire/input/usa.gpkg\")\n",
    "gdf_nifc = gpd.read_file(\"../data/wildfire/input/nifc_geographic_areas.gpkg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfb311c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   State  Number_of_NIFC_Regions  \\\n",
      "4             California                       5   \n",
      "28                Nevada                       5   \n",
      "5               Colorado                       4   \n",
      "36              Oklahoma                       4   \n",
      "37                Oregon                       4   \n",
      "12                 Idaho                       4   \n",
      "16                Kansas                       3   \n",
      "25              Missouri                       3   \n",
      "23             Minnesota                       3   \n",
      "34          North Dakota                       3   \n",
      "31            New Mexico                       3   \n",
      "26               Montana                       3   \n",
      "50               Wyoming                       3   \n",
      "41          South Dakota                       3   \n",
      "44                  Utah                       3   \n",
      "13              Illinois                       2   \n",
      "17              Kentucky                       2   \n",
      "1                 Alaska                       2   \n",
      "2                Arizona                       2   \n",
      "48         West Virginia                       2   \n",
      "47            Washington                       2   \n",
      "43                 Texas                       2   \n",
      "46              Virginia                       2   \n",
      "35                  Ohio                       2   \n",
      "42             Tennessee                       2   \n",
      "27              Nebraska                       2   \n",
      "15                  Iowa                       2   \n",
      "8   District of Columbia                       2   \n",
      "3               Arkansas                       2   \n",
      "14               Indiana                       2   \n",
      "20              Maryland                       2   \n",
      "6            Connecticut                       1   \n",
      "7               Delaware                       1   \n",
      "0                Alabama                       1   \n",
      "10               Georgia                       1   \n",
      "18             Louisiana                       1   \n",
      "11                Hawaii                       1   \n",
      "9                Florida                       1   \n",
      "30            New Jersey                       1   \n",
      "22              Michigan                       1   \n",
      "21         Massachusetts                       1   \n",
      "19                 Maine                       1   \n",
      "24           Mississippi                       1   \n",
      "33        North Carolina                       1   \n",
      "32              New York                       1   \n",
      "29         New Hampshire                       1   \n",
      "38          Pennsylvania                       1   \n",
      "39          Rhode Island                       1   \n",
      "40        South Carolina                       1   \n",
      "45               Vermont                       1   \n",
      "49             Wisconsin                       1   \n",
      "\n",
      "                      NIFC_Regions  \n",
      "4   [NWCC, SWCC, ONCC, GBCC, OSCC]  \n",
      "28  [NWCC, SWCC, ONCC, GBCC, OSCC]  \n",
      "5         [SWCC, GBCC, RMCC, SACC]  \n",
      "36        [SWCC, EACC, RMCC, SACC]  \n",
      "37        [NRCC, GBCC, NWCC, ONCC]  \n",
      "12        [NRCC, GBCC, NWCC, RMCC]  \n",
      "16              [EACC, RMCC, SACC]  \n",
      "25              [EACC, RMCC, SACC]  \n",
      "23              [EACC, NRCC, RMCC]  \n",
      "34              [EACC, NRCC, RMCC]  \n",
      "31              [SWCC, RMCC, SACC]  \n",
      "26              [NRCC, GBCC, RMCC]  \n",
      "50              [NRCC, GBCC, RMCC]  \n",
      "41              [EACC, NRCC, RMCC]  \n",
      "44              [SWCC, GBCC, RMCC]  \n",
      "13                    [EACC, SACC]  \n",
      "17                    [EACC, SACC]  \n",
      "1                     [AICC, ONCC]  \n",
      "2                     [SWCC, GBCC]  \n",
      "48                    [EACC, SACC]  \n",
      "47                    [NRCC, NWCC]  \n",
      "43                    [SWCC, SACC]  \n",
      "46                    [EACC, SACC]  \n",
      "35                    [EACC, SACC]  \n",
      "42                    [EACC, SACC]  \n",
      "27                    [EACC, RMCC]  \n",
      "15                    [EACC, RMCC]  \n",
      "8                     [EACC, SACC]  \n",
      "3                     [EACC, SACC]  \n",
      "14                    [EACC, SACC]  \n",
      "20                    [EACC, SACC]  \n",
      "6                           [EACC]  \n",
      "7                           [EACC]  \n",
      "0                           [SACC]  \n",
      "10                          [SACC]  \n",
      "18                          [SACC]  \n",
      "11                          [ONCC]  \n",
      "9                           [SACC]  \n",
      "30                          [EACC]  \n",
      "22                          [EACC]  \n",
      "21                          [EACC]  \n",
      "19                          [EACC]  \n",
      "24                          [SACC]  \n",
      "33                          [SACC]  \n",
      "32                          [EACC]  \n",
      "29                          [EACC]  \n",
      "38                          [EACC]  \n",
      "39                          [EACC]  \n",
      "40                          [SACC]  \n",
      "45                          [EACC]  \n",
      "49                          [EACC]  \n"
     ]
    }
   ],
   "source": [
    "# 1. Ensure both GeoDataFrames have the same CRS (Coordinate Reference System)\n",
    "gdf_nifc = gdf_nifc.to_crs(gdf_usa.crs)\n",
    "\n",
    "# 2. Dissolve the state geometries to ensure each state is represented by a single geometry\n",
    "gdf_usa_dissolved = gdf_usa.dissolve(by='adm1_name', as_index=False)\n",
    "\n",
    "# 3. Perform a spatial join\n",
    "joined = gpd.sjoin(gdf_usa_dissolved, gdf_nifc, how='left', predicate='intersects')\n",
    "\n",
    "# Group by state and aggregate both count and list of NIFC regions\n",
    "result = (joined.groupby('adm1_name')\n",
    "          .agg({\n",
    "              'GACCAbbreviation': [('Number_of_NIFC_Regions', 'nunique'),\n",
    "                          ('NIFC_Regions', lambda x: list(set(x)))]\n",
    "          })\n",
    "          .reset_index())\n",
    "\n",
    "# Flatten column names\n",
    "result.columns = ['State', 'Number_of_NIFC_Regions', 'NIFC_Regions']\n",
    "\n",
    "# Sort by number of regions (descending)\n",
    "result = result.sort_values('Number_of_NIFC_Regions', ascending=False)\n",
    "\n",
    "# Display the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b478e849",
   "metadata": {},
   "source": [
    "## Q4: Find the year with the highest suppression cost per acre of human-caused fire. What was the cost per acre, rounded to the nearest cent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ac300f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_costs = pd.read_csv(\"../data/wildfire/input/nifc_suppression_costs.csv\", delimiter='\\t')\n",
    "df_acres = pd.read_csv(\"../data/wildfire/input/nifc_human_caused_acres.csv\", delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a41e763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year with highest suppression cost per acre: 2023\n",
      "Cost per acre: $2065.10\n",
      "Total acres burned: 1,533,245\n",
      "Total suppression cost: $3,166,300,000.00\n"
     ]
    }
   ],
   "source": [
    "# Clean and convert acres data\n",
    "df_acres['Total_clean'] = df_acres['Total'].str.replace(',', '').astype(float)\n",
    "\n",
    "# Clean and convert costs data\n",
    "df_costs['Total_clean'] = df_costs['Total'].str.replace('$', '').str.replace(',', '').astype(float)\n",
    "\n",
    "# Merge the two dataframes on Year\n",
    "merged_df = pd.merge(df_acres, df_costs, on='Year')\n",
    "\n",
    "# Calculate cost per acre\n",
    "merged_df['cost_per_acre'] = merged_df['Total_clean_y'] / merged_df['Total_clean_x']\n",
    "\n",
    "# Find the year with highest cost per acre\n",
    "max_cost_year = merged_df.loc[merged_df['cost_per_acre'].idxmax()]\n",
    "\n",
    "# Format the output\n",
    "print(f\"Year with highest suppression cost per acre: {max_cost_year['Year']}\")\n",
    "print(f\"Cost per acre: ${max_cost_year['cost_per_acre']:.2f}\")\n",
    "print(f\"Total acres burned: {max_cost_year['Total_clean_x']:,.0f}\")\n",
    "print(f\"Total suppression cost: ${max_cost_year['Total_clean_y']:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eebdb1a",
   "metadata": {},
   "source": [
    "## Q5: On average, how many more annual fires are reported by NOAA compared to NIFC since 2000? Round to the nearest whole number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca511bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noaa = pd.read_csv(\"../data/wildfire/input/noaa_wildfires.csv\", skiprows=3)\n",
    "df_nifc = pd.read_csv(\"../data/wildfire/input/nifc_wildfires.csv\", delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04806230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On average, NOAA reports -1,039 more fires per year than NIFC\n"
     ]
    }
   ],
   "source": [
    "# Convert NIFC fires column to numeric, removing commas\n",
    "df_nifc['Fires_clean'] = df_nifc['Fires'].str.replace(',', '').astype(int)\n",
    "\n",
    "# Convert NOAA Date to year and group by year, summing the fires\n",
    "df_noaa['Year'] = df_noaa['Date'].astype(str).str[:4].astype(int)\n",
    "noaa_annual = df_noaa.groupby('Year')['Number of Fires'].sum().reset_index()\n",
    "\n",
    "# Merge the two dataframes\n",
    "merged_df = pd.merge(\n",
    "    noaa_annual, \n",
    "    df_nifc[['Year', 'Fires_clean']], \n",
    "    on='Year',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Calculate difference (NOAA - NIFC) and take mean\n",
    "avg_difference = (merged_df['Number of Fires'] - merged_df['Fires_clean']).mean()\n",
    "\n",
    "# Round to nearest whole number\n",
    "rounded_difference = round(avg_difference)\n",
    "\n",
    "print(f\"On average, NOAA reports {rounded_difference:,} more fires per year than NIFC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697c8886",
   "metadata": {},
   "source": [
    "## Q6: What is the correlation between (1) the difference between the number of NOAA and NIFC-reported fires and (2) the difference between the acres burned by NOAA and NIFC-reported fires, on an annual basis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d1e08cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noaa = pd.read_csv(\"../data/wildfire/input/noaa_wildfires.csv\", skiprows=3)\n",
    "df_nifc = pd.read_csv(\"../data/wildfire/input/nifc_wildfires.csv\", delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7dfa15f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation coefficient: 0.519\n"
     ]
    }
   ],
   "source": [
    "# Clean NIFC data\n",
    "df_nifc['Fires_clean'] = df_nifc['Fires'].str.replace(',', '').astype(int)\n",
    "df_nifc['Acres_clean'] = df_nifc['Acres'].str.replace('*', '', regex=False).str.replace(',', '').astype(int)\n",
    "\n",
    "# Convert NOAA Date to year and group by year, summing both fires and acres\n",
    "df_noaa['Year'] = df_noaa['Date'].astype(str).str[:4].astype(int)\n",
    "noaa_annual = df_noaa.groupby('Year').agg({\n",
    "    'Number of Fires': 'sum',\n",
    "    'Acres Burned': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Merge the two dataframes\n",
    "merged_df = pd.merge(\n",
    "    noaa_annual, \n",
    "    df_nifc[['Year', 'Fires_clean', 'Acres_clean']], \n",
    "    on='Year',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Calculate differences\n",
    "merged_df['fire_difference'] = merged_df['Number of Fires'] - merged_df['Fires_clean']\n",
    "merged_df['acres_difference'] = merged_df['Acres Burned'] - merged_df['Acres_clean']\n",
    "\n",
    "# Calculate correlation\n",
    "correlation = merged_df['fire_difference'].corr(merged_df['acres_difference'])\n",
    "\n",
    "print(f\"Correlation coefficient: {correlation:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001f484c",
   "metadata": {},
   "source": [
    "## Q7: Which geographic area had the most anomalous year (by Z-score) in terms of total acres burned compared to its historical annual average, and what year was it in?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62cabdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_human = pd.read_csv(\"../data/wildfire/input/nifc_human_caused_acres.csv\", delimiter='\\t')\n",
    "df_lightning = pd.read_csv(\"../data/wildfire/input/nifc_lightning_caused_acres.csv\", delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b59a49eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most anomalous year was 2020 in Northern California\n",
      "Acres burned: 15,490,121,549,012\n",
      "Historical average: 757,286,558,096\n",
      "Z-score: 4.68\n",
      "This was 4.68 standard deviations from the mean\n"
     ]
    }
   ],
   "source": [
    "# Combine human and lightning caused fires\n",
    "def process_dataframes(df_human, df_lightning):\n",
    "    # Clean column names by removing asterisks\n",
    "    df_human.columns = df_human.columns.str.replace('*', '')\n",
    "    df_lightning.columns = df_lightning.columns.str.replace('*', '')\n",
    "    \n",
    "    # Get geographic columns (exclude Year and Total)\n",
    "    geo_cols = [col for col in df_human.columns if col not in ['Year', 'Total']]\n",
    "    \n",
    "    # Sum the dataframes\n",
    "    df_total = df_human.copy()\n",
    "    for col in geo_cols:\n",
    "        df_total[col] = df_human[col] + df_lightning[col]\n",
    "    \n",
    "    # Replace 'N/A' with np.nan and convert to numeric\n",
    "    for col in geo_cols:\n",
    "        df_total[col] = pd.to_numeric(df_total[col].replace('N/A', np.nan).str.replace(',', ''))\n",
    "    \n",
    "    return df_total, geo_cols\n",
    "\n",
    "def find_most_anomalous(df_total, geo_cols):\n",
    "    # Calculate z-score for each geographic area and year\n",
    "    anomalies = pd.DataFrame()\n",
    "    anomalies['Year'] = df_total['Year']\n",
    "    \n",
    "    for col in geo_cols:\n",
    "        mean = df_total[col].mean()\n",
    "        std = df_total[col].std()\n",
    "        anomalies[col] = (df_total[col] - mean) / std\n",
    "    \n",
    "    # Find the most extreme z-score\n",
    "    # Use abs() to consider both positive and negative anomalies\n",
    "    max_anomaly = float('-inf')\n",
    "    max_area = ''\n",
    "    max_year = None\n",
    "    max_actual = None\n",
    "    max_mean = None\n",
    "    \n",
    "    for col in geo_cols:\n",
    "        abs_anomalies = abs(anomalies[col])\n",
    "        max_idx = abs_anomalies.idxmax()\n",
    "        if abs_anomalies[max_idx] > max_anomaly:\n",
    "            max_anomaly = abs_anomalies[max_idx]\n",
    "            max_area = col\n",
    "            max_year = df_total.loc[max_idx, 'Year']\n",
    "            max_actual = df_total.loc[max_idx, col]\n",
    "            max_mean = df_total[col].mean()\n",
    "    \n",
    "    return max_area, max_year, max_actual, max_mean, max_anomaly\n",
    "\n",
    "df_total, geo_cols = process_dataframes(df_human, df_lightning)\n",
    "\n",
    "# Find most anomalous case\n",
    "area, year, actual, mean, z_score = find_most_anomalous(df_total, geo_cols)\n",
    "\n",
    "print(f\"Most anomalous year was {year} in {area}\")\n",
    "print(f\"Acres burned: {actual:,.0f}\")\n",
    "print(f\"Historical average: {mean:,.0f}\")\n",
    "print(f\"Z-score: {z_score:.2f}\")\n",
    "print(f\"This was {abs(z_score):.2f} standard deviations from the mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5ce097",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
