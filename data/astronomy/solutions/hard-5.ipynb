{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87de4ff1-c454-40ab-802b-7c4b9fa18344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hard Q5\n",
    "# according to https://www.mathworks.com/help/aeroblks/nrlmsise00atmospheremodel.html\n",
    "# Answer: 4.638e-13\n",
    "# need pyatmos: !pip install pyatmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32e330ed-8816-4ad6-a73a-bdf0ccb275ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the latest EOP file 'finals2000A.all' from IERS\n",
      "\n",
      "Downloading the latest Leap Second file 'Leap_Second.dat' from IERS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from astropy.time import Time\n",
    "\n",
    "from pyatmos.msise.nrlmsise00_subfunc import gtd7,gtd7d\n",
    "from pyatmos.utils.utils import wraplon,hms_conver\n",
    "from pyatmos.class_atmos import ATMOS\n",
    "\n",
    "def nrlmsise00(t,\n",
    "               location,\n",
    "               f107A, \n",
    "               f107,\n",
    "               ap,\n",
    "               aph,\n",
    "               aphmode=True):\n",
    "    \"\"\"\n",
    "    This function is extracted from the nrlmsise00 algorithm from\n",
    "    pyatmos, that takes external F10.7A, F10.7, AP and AP_H data.\n",
    "    \"\"\"\n",
    "\n",
    "    lat,lon,h = location\n",
    "\n",
    "    # calculate the altitude above sea level from height\n",
    "    alt = h\n",
    "        \n",
    "    t = Time(t)\n",
    "    t_ymd = t.isot.split('T')[0]\n",
    "    t_yday = t.yday.split(':')\n",
    "    year,doy = int(t_yday[0]),int(t_yday[1])\n",
    "    hour,sec = hms_conver(int(t_yday[2]),int(t_yday[3]),float(t_yday[4]))\n",
    "    lst = hour + wraplon(lon)/15\n",
    "    if alt <= 80:\n",
    "        f107A,f107,ap,aph = 150,150,4,np.full(7,4)\n",
    "\n",
    "    lon_wrap = wraplon(lon)\n",
    "    inputp = {'doy':doy,'year':year,'sec':sec,'alt':alt,'g_lat':lat,'g_lon':lon_wrap,'lst':lst,\\\n",
    "              'f107A':f107A,'f107':f107,'ap':ap,'ap_a':aph}\n",
    "    \n",
    "    switches = np.ones(23)\n",
    "    if aphmode: switches[8] = -1 # -1 indicates the use of 3h geomagnetic index\n",
    "        \n",
    "    if alt > 500:\n",
    "        output = gtd7d(inputp,switches)\n",
    "    else:\n",
    "        output = gtd7(inputp,switches)\n",
    "\n",
    "    inputp['g_lon'] = lon   \n",
    "    params = {'Year':inputp['year'],'DOY':inputp['doy'],'SOD':inputp['sec'],'Lat':inputp['g_lat'],'Lon':inputp['g_lon'],'Alt':inputp['alt'],'LST':inputp['lst'],\\\n",
    "              'f107A':inputp['f107A'],'f107D':inputp['f107'],'ApD':inputp['ap'],'Ap3H':inputp['ap_a']}\n",
    "    rho = output['d']['RHO']          \n",
    "    T = (output['t']['TINF'],output['t']['TG'])\n",
    "    nd = {'He':output['d']['He'],'O':output['d']['O'],'N2':output['d']['N2'],'O2':output['d']['O2'],'Ar':output['d']['AR'],'H':output['d']['H'],'N':output['d']['N'],'ANM O':output['d']['ANM O']}\n",
    "\n",
    "    info = {'rho':rho,'T':output['t']['TG'],'nd':nd}\n",
    "\n",
    "    return ATMOS(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b4cd391-024c-49be-8ec9-e7331150693b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta, timezone\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import timedelta, timezone, datetime\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# helper : mean Ap for the 3-hour window that starts at `t_bin_start`\n",
    "# ------------------------------------------------------------------\n",
    "def _mean_ap3h(omni: pd.DataFrame, t_bin_start: datetime) -> float:\n",
    "    \"\"\"Return the average Ap over [t, t+3 h).\"\"\"\n",
    "    win = omni.loc[t_bin_start : t_bin_start + timedelta(hours=3) - timedelta(seconds=1), 'ap']\n",
    "    return float(win.mean())\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# main entry --------------------------------------------------------\n",
    "def build_msis_inputs(omni: pd.DataFrame, when_utc: datetime) -> dict:\n",
    "    \"\"\"\n",
    "    Build NRLMSISE-00 inputs from an hourly OMNI-2 dataframe.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    omni : DataFrame with columns 'f10.7' and 'ap'; index UTC & monotonic.\n",
    "    when_utc : datetime (tz-aware)  – model evaluation time.\n",
    "\n",
    "    Returns dict with keys: f107A, f107, ap, aph (np.ndarray len 7).\n",
    "    These are data needed for the nrlmsise-00\n",
    "    according to https://www.mathworks.com/help/aeroblks/nrlmsise00atmospheremodel.html\n",
    "    \"\"\"\n",
    "    if when_utc.tzinfo is None:\n",
    "        raise ValueError(\"`when_utc` must be timezone-aware (UTC)\")\n",
    "\n",
    "    # ---------- daily values --------------------------------------\n",
    "    day          = when_utc.date()\n",
    "    day_rows     = omni.index.date == day\n",
    "    if not day_rows.any():\n",
    "        raise ValueError(\"No OMNI data for that day\")\n",
    "\n",
    "    # “daily Ap” = mean of AP measurement\n",
    "    ap_daily = float(omni.loc[day_rows, 'ap'].mean())\n",
    "    # daily F10.7 is in the 00:00 UT row\n",
    "    f107       = float(omni.loc[day_rows, 'f10.7'].iloc[0])\n",
    "\n",
    "    # 81-day running average of F10.7 **up to but not including today**\n",
    "    start81    = day - timedelta(days=81)\n",
    "    mask81     = (omni.index.date >= start81) & (omni.index.date < day)\n",
    "    f107A_ser  = (omni.loc[mask81, 'f10.7']\n",
    "                       .groupby(omni.loc[mask81].index.date).first())\n",
    "    f107A      = float(f107A_ser.mean()) if len(f107A_ser) == 81 else None\n",
    "\n",
    "    # ---------- 3-hour Ap vector (aph[1] … aph[6]) ----------------\n",
    "    # find the start of the 3-hour bin that contains `when_utc`\n",
    "    t0 = when_utc.replace(minute=0, second=0, microsecond=0)\n",
    "    bin_start_now = t0 - timedelta(hours=t0.hour % 3)\n",
    "\n",
    "    def ap3(shift_h):\n",
    "        return _mean_ap3h(omni, bin_start_now - timedelta(hours=shift_h))\n",
    "\n",
    "    aph = np.empty(7, dtype=float)\n",
    "    aph[0] = ap_daily\n",
    "    aph[1] = ap3(0)          # centred on model time\n",
    "    aph[2] = ap3(3)\n",
    "    aph[3] = ap3(6)\n",
    "    aph[4] = ap3(9)\n",
    "\n",
    "    # mean of 8 bins whose centres lie 26 - 57 h before model time\n",
    "    bins = [ap3(h) for h in range(12, 34, 3)]\n",
    "    aph[5] = float(np.mean(bins))\n",
    "\n",
    "    # mean of 8 bins whose centres lie 26 - 57 h before model time\n",
    "    bins = [ap3(h) for h in range(36, 58, 3)]\n",
    "    aph[6] = float(np.mean(bins))\n",
    "\n",
    "    return {\n",
    "        \"f107A\": f107A,\n",
    "        \"f107\":  f107,\n",
    "        \"ap\":    ap_daily,\n",
    "        \"aph\":   aph,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af92a447-c001-4ec5-9d6d-b001b99ffebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Public API\n",
    "# ----------------------------------------------------------------------\n",
    "def load_swarmb_density_year(folder: str | Path, year: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load every Swarm-B neutral-density POD text file for the given *year*\n",
    "    into a single tidy DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    folder : str | Path\n",
    "        Directory that contains files named like\n",
    "        `SB_DNS_POD_yyyy_mm_v02.txt` (or .asc, .dat, …―wild-cards ok).\n",
    "    year : int\n",
    "        Four-digit year (e.g. 2024).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Columns exactly match those in the files:\n",
    "        ['alt_m', 'lon_deg', 'lat_deg', 'lst_h',\n",
    "         'arglat_deg', 'rho_kg_m3', 'time_system'],\n",
    "        indexed by timezone-aware pandas.DatetimeIndex (UTC),\n",
    "        sorted in ascending order.\n",
    "    \"\"\"\n",
    "    folder = Path(folder).expanduser()\n",
    "    pattern = re.compile(rf\"SB_DNS_POD_{year:04d}_(\\d{{2}}).*\\.txt$\", re.I)\n",
    "\n",
    "    # ---------------- Collect files ----------------\n",
    "    files = sorted(p for p in folder.iterdir() if pattern.match(p.name))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No Swarm-B POD files for {year} in {folder}\")\n",
    "\n",
    "    frames = []\n",
    "    for fp in files:\n",
    "        # Skip comment header lines beginning with '#'\n",
    "        with fp.open(\"r\", encoding=\"utf-8\") as fh:\n",
    "            skip = 0\n",
    "            for line in fh:\n",
    "                if not line.startswith(\"#\"):\n",
    "                    break\n",
    "                skip += 1\n",
    "\n",
    "        # Fixed-width columns separated by *one* space ⇒ use delim_whitespace\n",
    "        df = pd.read_csv(\n",
    "            fp,\n",
    "            sep=r'\\s+',\n",
    "            skiprows=skip,\n",
    "            header=None,\n",
    "            names=[\n",
    "                \"date\", \"time\", \"time_system\",\n",
    "                \"alt_m\", \"lon_deg\", \"lat_deg\",\n",
    "                \"lst_h\", \"arglat_deg\", \"rho_kg_m3\"\n",
    "            ],\n",
    "            dtype={\n",
    "                \"time_system\": \"category\",\n",
    "                \"alt_m\": np.float64,\n",
    "                \"lon_deg\": np.float64,\n",
    "                \"lat_deg\": np.float64,\n",
    "                \"lst_h\": np.float32,\n",
    "                \"arglat_deg\": np.float64,\n",
    "                \"rho_kg_m3\": np.float64,\n",
    "            },\n",
    "        )\n",
    "\n",
    "        # Combine date+time, make timezone-aware (treat GPS as UTC)\n",
    "        ts = pd.to_datetime(df[\"date\"] + \" \" + df[\"time\"], utc=True)\n",
    "        df.index = ts\n",
    "        frames.append(df.drop(columns=[\"date\", \"time\"]))\n",
    "\n",
    "    # ---------------- Concatenate & sort ----------------\n",
    "    out = (\n",
    "        pd.concat(frames, copy=False)\n",
    "        .sort_index()\n",
    "        .rename_axis(\"datetime_utc\")\n",
    "    )\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfe22626-64c5-4e29-991b-b728df8e8835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NRLMSISE-00 RMSE vs Swarm-B for 2024  :  4.638e-13  kg/m^3\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from datetime import timezone\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "omni = pd.read_fwf(\n",
    "    Path(\"../data_local/omni2_low_res/omni2_2024.dat\").expanduser(),          # << path\n",
    "    widths=[4, 4, 3, 5, 3, 3, 4, 4, 6, 6, 6, 6,\n",
    "            6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
    "            9, 6, 6, 6, 6, 6, 6, 9, 6, 6, \n",
    "            6, 6, 6, 7, 7, 6,\n",
    "            3, 4, 6, 5, 10, 9, 9, 9, 9, 9, 3,\n",
    "            4, 6, 6, 6, 6, 5], header=None\n",
    ")\n",
    "omni = pd.concat([omni, pd.read_fwf(\n",
    "    Path(\"../data_local/omni2_low_res/omni2_2023.dat\").expanduser(),          # << path\n",
    "    widths=[4, 4, 3, 5, 3, 3, 4, 4, 6, 6, 6, 6,\n",
    "            6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
    "            9, 6, 6, 6, 6, 6, 6, 9, 6, 6, \n",
    "            6, 6, 6, 7, 7, 6,\n",
    "            3, 4, 6, 5, 10, 9, 9, 9, 9, 9, 3,\n",
    "            4, 6, 6, 6, 6, 5], header=None\n",
    ")])\n",
    "omni.columns = [\n",
    "    'year', 'doy', 'hour', 'brn', 'imf_id', 'sw_id', 'n_imf', 'n_sw', \n",
    "    'B_mag_avg', 'B_vec_mag', 'B_lat', 'B_long',\n",
    "    'Bx_GSE', 'By_GSE', 'Bz_GSE', 'By_GSM', 'Bz_GSM',\n",
    "    'sigma_B_mag', 'sigma_B_vec', 'sigma_Bx', 'sigma_By', 'sigma_Bz',\n",
    "    'proton_temp', 'proton_density', 'flow_speed', 'flow_long', 'flow_lat',\n",
    "    'Na_Np', 'flow_pressure', 'sigma_T', 'sigma_N', 'sigma_V',\n",
    "    'sigma_phi_V', 'sigma_theta_V', 'sigma_Na_Np',\n",
    "    'electric_field', 'plasma_beta', 'alfven_mach',\n",
    "    'Kp', 'sunspot', 'Dst', 'AE', 'pf_1MeV', 'pf_2MeV', 'pf_4MeV', 'pf_10MeV', 'pf_30MeV', 'pf_60MeV', 'flag',\n",
    "    'ap', 'f10.7', 'PC_N', 'AL', 'AU', 'mach_number'\n",
    "]\n",
    "omni['Kp'] /= 10\n",
    "\n",
    "omni['t'] = omni.apply(\n",
    "    lambda r: datetime(int(r.year), 1, 1, tzinfo=timezone.utc)\n",
    "              + timedelta(days=r.doy-1, hours=r.hour),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "omni = (omni\n",
    "        .set_index('t').sort_index())\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 1.  INPUTS -----------------------------------------------------------\n",
    "#    – omni  : hourly OMNI-2 dataframe (tz-aware, UTC, monotonic)\n",
    "#    – build_msis_inputs : function we wrote earlier\n",
    "#    – nrlmsise00        : user-supplied wrapper that returns .rho\n",
    "#    – load_swarmb_density_year (given in the prompt)\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# --- a)  Swarm-B neutral density for 2024 -----------------------------\n",
    "swarm_folder = \"../data_local/swarmb\"           #  << your path\n",
    "swarm = load_swarmb_density_year(swarm_folder, 2024)\n",
    "\n",
    "# average everything to the *nearest* whole hour\n",
    "swarm_hr = swarm[(swarm.index.minute == 0) &\n",
    "                 (swarm.index.second == 0) &\n",
    "                 (swarm.index.microsecond == 0)].copy()\n",
    "\n",
    "\n",
    "# --- b)  make sure OMNI covers 81 d back from 2024-01-01 --------------\n",
    "first_needed = pd.Timestamp(\"2023-10-12\", tz=\"UTC\")   # 81 d before 2024-01-01\n",
    "if omni.index.min() > first_needed:\n",
    "    raise ValueError(\"OMNI file does not start early enough for f107A\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2.  SCAN EVERY HOUR, RUN MODEL, COLLECT PREDICTIONS ------------------\n",
    "# ---------------------------------------------------------------------\n",
    "pred, obs = [], []\n",
    "\n",
    "for ts, row in swarm_hr.iterrows():\n",
    "    try:\n",
    "        inp = build_msis_inputs(omni, ts)      # may raise if day missing\n",
    "        if inp[\"f107A\"] is None:               # skip until 81-day window exists\n",
    "            continue\n",
    "    except Exception:\n",
    "        continue                               # skip hours missing OMNI data\n",
    "\n",
    "    location = (\n",
    "        row[\"lat_deg\"],\n",
    "        row[\"lon_deg\"],\n",
    "        row[\"alt_m\"] / 1000.0                  # MSIS expects altitude [km]\n",
    "    )\n",
    "\n",
    "    rho_model = nrlmsise00(\n",
    "        ts.to_pydatetime(), location,\n",
    "        inp[\"f107A\"], inp[\"f107\"],\n",
    "        inp[\"ap\"],   inp[\"aph\"],\n",
    "        aphmode=True\n",
    "    ).rho\n",
    "\n",
    "    pred.append(rho_model)\n",
    "    obs .append(row[\"rho_kg_m3\"])\n",
    "\n",
    "pred = np.asarray(pred)\n",
    "obs  = np.asarray(obs)\n",
    "\n",
    "rmse = float(np.sqrt(np.mean((pred - obs) ** 2)))\n",
    "print(f\"NRLMSISE-00 RMSE vs Swarm-B for 2024  :  {rmse:.3e}  kg/m^3\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
