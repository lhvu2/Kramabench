{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hard 4. In the STORM-AI Warmup dataset (version 2), for the 10-day period from 2018-10-01 to 2018-10-10, compare all available variables coming from: OMNI2 (solar wind parameters, IMF measurements, geomagnetic indices, and proton flux metrics embedded within OMNI2),and Sat_Density (mean atmospheric density near Swarm-A orbit), against the Swarm-A satellite's hourly altitude change (change_altitude per hour, computed from POD SP3 data). Which variable shows the strongest Pearson correlation (positive or negative) with the hourly change of altitude?\n",
    "# - Proton_flux_>30_Mev with a Pearson correlation coefficient of r = -0.166."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup and Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 2. Helper: Parse SP3 file for Swarm-A (PRN L47)\n",
    "def parse_sp3(sp3_path):\n",
    "    \"\"\"\n",
    "    Reads a Swarm-A SP3 file and returns a DataFrame with datetime and altitude.\n",
    "    \"\"\"\n",
    "    times, xs, ys, zs = [], [], [], []\n",
    "    current_time = None\n",
    "    with open(sp3_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('*'):\n",
    "                ts_str = line[2:].strip()\n",
    "                ts_parts = ts_str.split()\n",
    "                date_str = ' '.join(ts_parts[:6])\n",
    "                current_time = pd.to_datetime(date_str, format=\"%Y %m %d %H %M %S.%f\")\n",
    "            elif line.startswith('PL47'):\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 4:\n",
    "                    x = float(parts[1])\n",
    "                    y = float(parts[2])\n",
    "                    z = float(parts[3])\n",
    "                    times.append(current_time)\n",
    "                    xs.append(x)\n",
    "                    ys.append(y)\n",
    "                    zs.append(z)\n",
    "    df = pd.DataFrame({\n",
    "        'datetime': times,\n",
    "        'X_km': xs,\n",
    "        'Y_km': ys,\n",
    "        'Z_km': zs\n",
    "    }).set_index('datetime')\n",
    "    df['alt_km'] = np.sqrt(df.X_km**2 + df.Y_km**2 + df.Z_km**2) - 6371.0\n",
    "    return df[['alt_km']]\n",
    "\n",
    "# 3. Build hourly ∆altitude series\n",
    "sp3_files = sorted(glob.glob(\n",
    "    '../data_local/swarm/POD/SW_OPER_SP3ACOM_2__201810??T235942_201810??T235942_0201/*.sp3'\n",
    "))\n",
    "alt_dfs = [parse_sp3(fn) for fn in sp3_files]\n",
    "alt_all = pd.concat(alt_dfs).sort_index()\n",
    "\n",
    "# ensure datetime index\n",
    "if not isinstance(alt_all.index, pd.DatetimeIndex):\n",
    "    alt_all.index = pd.to_datetime(alt_all.index)\n",
    "\n",
    "# Resample to hourly and compute delta altitude\n",
    "alt_hourly = alt_all.resample('1h').mean().dropna()\n",
    "alt_hourly['delta_alt'] = alt_hourly['alt_km'].diff()\n",
    "alt_hourly = alt_hourly.dropna()\n",
    "print(f\"Swarm-A Δaltitude records: {alt_hourly.shape}\")\n",
    "\n",
    "# 4. Load OMNI2 data\n",
    "omni = pd.read_csv(\n",
    "    '../data_local/STORM-AI/warmup/v2/OMNI2/omni2-wu590-20181001_to_20181130.csv',\n",
    "    parse_dates=['Timestamp'],\n",
    "    index_col='Timestamp'\n",
    ")\n",
    "omni10 = omni.loc['2018-10-01':'2018-10-10']\n",
    "omni10 = omni10.resample('1h').mean().dropna()\n",
    "print(f\"OMNI2 records: {omni10.shape}\")\n",
    "\n",
    "# 5. Load Sat_Density\n",
    "sd_files = sorted(glob.glob(\n",
    "    '../data_local/STORM-AI/warmup/v2/Sat_Density/swarma-wu57[0-2]-201810*_to_201810*.csv'\n",
    "))\n",
    "sd_list = []\n",
    "for fn in sd_files:\n",
    "    df = pd.read_csv(fn, parse_dates=['Timestamp'], index_col='Timestamp')\n",
    "    df = df.rename(columns={'Orbit Mean Density (kg/m^3)': 'Orbit_Mean_Density'})\n",
    "    sd_list.append(df.loc['2018-10-01':'2018-10-10'])\n",
    "satdens = pd.concat(sd_list)\n",
    "satdens = satdens.resample('1h').mean().dropna()\n",
    "print(f\"Sat_Density records: {satdens.shape}\")\n",
    "\n",
    "# 6. Merge Δaltitude, OMNI2, Sat_Density\n",
    "df = (\n",
    "    alt_hourly[['delta_alt']]\n",
    "    .join(omni10, how='inner')\n",
    "    .join(satdens, how='inner')\n",
    "    .dropna()\n",
    ")\n",
    "print(f\"▶ Final merged dataset shape: {df.shape}\")\n",
    "\n",
    "if df.empty:\n",
    "    raise RuntimeError(\"No overlapping data found.\")\n",
    "\n",
    "# 7. Compute Pearson correlations\n",
    "corrs = {}\n",
    "for col in df.columns:\n",
    "    if col == 'delta_alt':\n",
    "        continue\n",
    "    if df[col].nunique() <= 1:\n",
    "        continue  # Skip constant columns\n",
    "    r, _ = pearsonr(df['delta_alt'], df[col])\n",
    "    corrs[col] = r\n",
    "\n",
    "# Find the strongest absolute correlation\n",
    "best_metric = max(corrs, key=lambda k: abs(corrs[k]))\n",
    "best_r = corrs[best_metric]\n",
    "\n",
    "print(\"Most correlated metric:\")\n",
    "print(f\"  {best_metric} (Pearson r = {best_r:.3f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
