{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dd521e-6e5c-4e76-bbd9-a40264b84dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hard Q1:\n",
    "# Train a density prediction model using OMNI2 variables (f10.7_index, Kp_index, Dst_index_nT) and GOES variables (xrsb_flux_observed, xrsa_flux_observed) to forecast Swarm Alpha's atmospheric density 4 hours ahead. Specifically, use a 16-hour context window to project the input time series forward using a VAR(1) model, then fit a linear regression model to predict the next 4 hours of density. Use data from wu334 (OMNI/GOES: 2016-10-22 to 2016-10-23; Density: 2016-10-23 to 2016-10-24) for training, and wu335 (OMNI/GOES: 2016-10-25 to 2016-10-26; Density: 2016-10-29) for evaluation. Assume that all windows contain valid data. Note that the data for training VAR lies at the end of the OMNI2 and GOES input window, and the corresponding Swarm Alpha density data begins immediately afterward; i.e., they only overlap at a single timestamp where OMNI/GOES ends and Density begins. Report the RMSE between the predicted and observed density values over the 4-hour forecast window.\n",
    "# Answer: 1.211e-13 (kg/m^3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b8f71df-ddfd-4585-b2a7-bacffeb77fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of each DF: train_df 1441, test_df 1441, train_dens 73, test_dens 73\n",
      "Max projected F10.7 in wu334 in the next hour: 75.03476558600127\n",
      "rmse for the training data: 9.453565849322295e-27\n",
      "Max projected F10.7 in wu335 in the next hour: 77.14561587141694\n",
      "rMSE for 4-hour density prediction  –  train wu334, test wu335:  1.211e-13\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# --------------- data files -------------------------------------------------\n",
    "BASE_OMNI = Path(\"../../data/astronomy/input/STORM-AI/warmup/v2/OMNI2\").expanduser()\n",
    "BASE_GOES = Path(\"../../data/astronomy/input/STORM-AI/warmup/v2/GOES\").expanduser()\n",
    "BASE_DENS = Path(\"../../data/astronomy/input/STORM-AI/warmup/v2/Sat_Density\").expanduser()\n",
    "\n",
    "TRAIN_ID  = \"wu334\"\n",
    "TEST_ID   = \"wu335\"\n",
    "DATE_RE   = re.compile(r\"(\\d{8})_to_(\\d{8})\")\n",
    "\n",
    "# --------------- helper -----------------------------------------------------\n",
    "def span_overlap(s1, e1, s2, e2):\n",
    "    return not (e1 < s2 or e2 < s1)\n",
    "\n",
    "def files_covering(folder, prefix, start, end):\n",
    "    sel = []\n",
    "    for f in folder.glob(f\"*{prefix}*\"):\n",
    "        m = DATE_RE.search(f.name);  0\n",
    "        if not m: continue\n",
    "        s, e = map(pd.Timestamp, m.groups())\n",
    "        if span_overlap(s, e, start, end): sel.append(f)\n",
    "    if not sel:\n",
    "        raise FileNotFoundError(f\"{prefix}: no files for {start:%Y%m%d}-{end:%Y%m%d}\")\n",
    "    return sorted(sel)\n",
    "\n",
    "# --------------- columns ----------------------------------------------------\n",
    "OMNI_COLS = [\"f10.7_index\", \"Kp_index\", \"Dst_index_nT\"]\n",
    "GOES_COLS = [\"xrsb_flux_observed\", \"xrsa_flux_observed\", ]\n",
    "FEATS     = OMNI_COLS + GOES_COLS               \n",
    "\n",
    "# --------------- loader -----------------------------------------------------\n",
    "def load_df(fid, start, end):\n",
    "    omni = pd.concat(pd.read_csv(p, parse_dates=[\"Timestamp\"])\n",
    "                     for p in files_covering(BASE_OMNI, f\"omni2-{fid}\", start, end))\\\n",
    "            [[\"Timestamp\"] + OMNI_COLS]\n",
    "    omni['Kp_index'] /= 10\n",
    "\n",
    "    goes = pd.concat(pd.read_csv(p, parse_dates=[\"Timestamp\"])\n",
    "                     for p in files_covering(BASE_GOES, f\"goes-{fid}\", start, end))\\\n",
    "            [[\"Timestamp\"] + GOES_COLS]\n",
    "\n",
    "    dens = pd.concat(pd.read_csv(p, parse_dates=[\"Timestamp\"])\n",
    "                     for p in files_covering(BASE_DENS, f\"swarma-{fid}\", start, end))\\\n",
    "            [[\"Timestamp\", \"Orbit Mean Density (kg/m^3)\"]]\\\n",
    "            .rename(columns={\"Orbit Mean Density (kg/m^3)\": \"rho\"})\n",
    "\n",
    "    return (omni.merge(goes, on=\"Timestamp\", how=\"inner\")\n",
    "                .set_index(\"Timestamp\")\n",
    "                .sort_index()\n",
    "                .resample(\"1h\").mean(), \n",
    "            dens.set_index(\"Timestamp\")\n",
    "                .sort_index().resample(\"1h\").mean()\n",
    "           )\n",
    "\n",
    "# --------------- windows ----------------------------------------------------\n",
    "tr_start, tr_end   = pd.Timestamp(\"20161022\"), pd.Timestamp(\"20161023\")\n",
    "tr_rho_end         = tr_end + timedelta(days=1)\n",
    "\n",
    "te_start, te_end   = pd.Timestamp(\"20161025\"), pd.Timestamp(\"20161026\")\n",
    "te_rho_end         = te_end + timedelta(days=1)\n",
    "\n",
    "train_df, train_dens = load_df(TRAIN_ID, tr_start, tr_rho_end)\n",
    "test_df, test_dens  = load_df(TEST_ID,  te_start, te_rho_end)\n",
    "\n",
    "print(f\"Length of each DF: train_df {train_df.shape[0]}, test_df {test_df.shape[0]}, train_dens {train_dens.shape[0]}, test_dens {test_dens.shape[0]}\")\n",
    "\n",
    "# --------------- sample --------------------------------------------\n",
    "HIST = 16   # h of context\n",
    "H = 4       # forecast horizon\n",
    "\n",
    "def samples(df):\n",
    "    df = df.copy()\n",
    "    rows = []\n",
    "    win = df.loc[df.index[-HIST]:df.index[-1], FEATS]\n",
    "\n",
    "    # VAR(1) coefficients A (k×k)\n",
    "    Y, X = win.iloc[1:].values, win.iloc[:-1].values\n",
    "    A    = np.linalg.lstsq(X, Y, rcond=None)[0].T\n",
    "    y1   = (A @ win.iloc[-1].values.reshape(-1,1)).ravel()  # +1 h forecast\n",
    "    for _ in range(H): \n",
    "        rows.append(y1)\n",
    "        y1 = (A @ y1).ravel()\n",
    "\n",
    "    cols = [f\"{c}_f1h\" for c in FEATS]\n",
    "    return pd.DataFrame(rows, columns=cols)\n",
    "\n",
    "train_s   = samples(train_df)\n",
    "test_s    = samples(test_df)\n",
    "\n",
    "# --------------- linear regressor ---------------------------------------\n",
    "poly  = PolynomialFeatures(degree=1, include_bias=False)\n",
    "X_tr  = poly.fit_transform(train_s[[f\"{c}_f1h\" for c in FEATS]])\n",
    "y_tr  = train_dens[\"rho\"][1:1+H].values\n",
    "reg   = LinearRegression().fit(X_tr, y_tr)\n",
    "print(f\"Max projected F10.7 in wu334 in the next hour: {max(X_tr.T[0])}\")\n",
    "print(f\"rmse for the training data: {mean_squared_error(y_tr, reg.predict(X_tr)) ** (1/2)}\")\n",
    "\n",
    "X_te  = poly.transform(test_s[[f\"{c}_f1h\" for c in FEATS]])\n",
    "y_te  = test_dens[\"rho\"][1:1+H].values\n",
    "print(f\"Max projected F10.7 in wu335 in the next hour: {max(X_te.T[0])}\")\n",
    "rmse   = mean_squared_error(y_te, reg.predict(X_te)) ** (1/2)\n",
    "\n",
    "print(f\"rMSE for {H}-hour density prediction  –  train {TRAIN_ID}, test {TEST_ID}: {rmse: .3e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc83c6e-b40d-42a2-8f98-ff9ffc28777b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
